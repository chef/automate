#!/bin/bash
#shellcheck disable=SC2034

export HAB_ORIGIN=${HAB_ORIGIN:-chef}
# Bring studio-common to life
RECOMMENDED_HAB_VERSION="0.90.6"

GOLANGCILINTVERSION=1.21.0

# TODO(ssd) 2019-11-19: https://github.com/habitat-sh/habitat/issues/7219
unset SSL_CERT_FILE

# shellcheck disable=1090
if [ -d "${STUDIO_COMMON:-}" ]; then
  echo "STUDIO_COMMON override in effect; using $STUDIO_COMMON, not chef/studio-common habitat package"
  source "$STUDIO_COMMON/bin/studio-common"
else
  hab pkg install chef/studio-common
  source "$(hab pkg path chef/studio-common)/bin/studio-common"
fi

# Install busybox-static so script evaluations (e.g. #!/bin/bash) will work
# This ensures normal linux studios work like Docker studios
log_line "Install busybox-static & bash hart packages"
hab pkg install core/busybox-static >/dev/null
hab pkg binlink -d /bin core/busybox-static >/dev/null
hab pkg install core/bash >/dev/null
hab pkg binlink -d /bin/ -f core/bash >/dev/null

# TODO (tc) Let's get rid of this hard-coded config long-term.
# Elasticsearch
# TODO (tc) This should be https once certs are added, at which point
# the HTTP calls in the mocha tests that talk to ES in ingest-service
# will need to be updated to pass certs along.
export ES_VERSION=5.6.4
export ELASTICSEARCH_URL="http://localhost:10141"
export POSTGRESQL_URL="localhost:5432"
# Ingest
export INGEST_URL="https://localhost:10122"
export INGEST_HOST="localhost"
export INGEST_PORT=10122
# Automate Gateway service
export GATEWAY_URL="https://localhost:2000"
export GATEWAY_HOST="localhost"
export GATEWAY_PORT=2000

# Compiling with cgo require gcc to be in our path. We don't typically
# use cgo so we set CGO_ENABLED=0 by default in the studio.
export CGO_ENABLED=0

# Go >= 1.13 will assume this but we have tools like protoc extensions that
# look for it.
export GO111MODULE=on

# Specify where to put 'go installed' binaries
setup_gobin() {
    local vendor_hash
    vendor_hash=$(cat \
      /src/vendor/modules.txt \
      /src/components/automate-grpc/protoc-gen-policy/policy/policy.go \
      /src/components/automate-grpc/protoc-gen-policy/api/policy.proto \
      /src/components/automate-grpc/protoc-gen-policy/iam/policy.proto \
    | sha256sum | cut -c1-16)
    export GOBIN_BASE="/src/bin"
    GOBIN="${GOBIN_BASE}/${vendor_hash}"
    export GOBIN
    mkdir -p "$GOBIN"
}

setup_gobin

# Make 'go installed' binaries available in the PATH
export PATH=$PATH:$GOBIN

# Enable vendor mode by default
export GOFLAGS=-mod=vendor

# Delve Server port for remote debugging
export GO_DEBUG_PORT=2345

# Depot channel for Chef micro-services
export CHEF_CHANNEL=dev

# Flag that will allow us detect when are we in dev mode inside any a2 component
export CHEF_DEV_ENVIRONMENT=true

# minimal(fast) hart compression level for dev
export HAB_HART_COMPRESSION_LEVEL=0

getting_started << GETTING_STARTED

Welcome to the Habitat-based development environment for the Automate mono-repo!

===== Deploy Automate =====

    To get started, use this to start the deployment service, download the latest 'dev' images for
    each service, and spin up Automate. (when you don't need local UI development)

        # start_all_services

    If you need to develop against the UI.

        # build components/automate-ui-devproxy/
        # start_automate_ui_background
        # start_all_services

    See ./dev-docs/ui-development.md for additional information.

===== Rebuild Components and Hot-load the Results =====

    After Automate is running, you can rebuild an entire component's hab package from source,
    then HOT LOAD IT INTO YOUR DEPLOY, replacing the dev image that was there previously.
    (Use 'build' instead of 'rebuild' if you want to check dependencies also.)

        # rebuild components/<COMPONENT>

===== Rebuild just the Go Binary =====

    If you have Go changes but no hab package changes, you can rebuild just the Go binary for your component.
    This works for both hab packages you've already built AND packages initially downloaded from the chef depot.
    This is slightly faster than 'rebuild' described above, but 'hab sup status' will not show a local origin
    like 'rebuild' does (so you won't be able to tell at a glance which components you have built locally).

        # go_update_component COMPONENT_NAME

===== Helpful Commands =====

    Get a fully-permissioned token with 'get_admin_token'. It's also idempotent,
    so you'll get the same token every time after the first run and can do things like:

        # curl --insecure -H "api-token \$(get_admin_token)" https://localhost/api/v0/version

    Load various data sets with 'chef_load_actions' or 'chef_load_nodes'.

For a complete walkthrough of the dev environment, see ./README.md and ./dev-docs/DEV_ENVIRONMENT.md.
Also try 'describe' at the hab studio prompt for a summary of available commands.

GETTING_STARTED

# Memory check. Because we all always forget to change the docker preferences
# when we re-install it
total_memory_kb=$(grep MemTotal /proc/meminfo | grep -o -E '[[:digit:]]+')
# 8 gigs == 8164340kb, subtract a few MB so we can just do a less than
# comp and to account for the fact that MemTotal is the physical ram
# reported by the BIOS less the kernel binary code and some other
# reserved regions.
if (( total_memory_kb < 8000000 )); then
  warn "!!!"
  warn "This system has less than 8Gb of RAM. You will not be able to run a full Automate deployment."
  warn "!!!"
fi


document "start_all_services" <<DOC
  Simple wrapper for 'start_deployment_service' and 'chef-automate dev deployinate'.
  Also applies a license (if present), creates IAM v2 dev users, and upgrades IAM to v2.
DOC
start_all_services() {
  start_deployment_service
  chef-automate dev deployinate
  if [[ -f "/src/dev/license.jwt" ]]; then
     chef-automate license apply "/src/dev/license.jwt"
  fi
  chef-automate dev create-iam-dev-users
}

document "get_admin_token" <<DOC
  This will idempotently generate an API token that has universal access for all your dev / curl needs.
DOC
get_admin_token() {
  check_if_deployinate_started || return 1
  if [ -f /tmp/admin_token ]; then
    cat /tmp/admin_token
  else
    # note: we don't have to suppress stderr, $(get_api_token) won't capture it.
    date +%s | xargs -I % chef-automate iam token create admin-token-% --admin >/tmp/admin_token || return 1
    cat /tmp/admin_token
  fi
}

document "check_if_deployinate_started" <<DOC
  Returns 0 if deployinate is up or 1 if not and a relevant error.
DOC
check_if_deployinate_started() {
  if ! type chef-automate > /dev/null 2>&1; then
    error "The deploy service has not been installed."
    log_line "Run '${GREEN}start_deployment_service${NC}' to consume the dev channel hart or '${GREEN}build components/automate-deployment${NC}' to build from source."
    return 1
  fi

  if ! chef-automate status > /dev/null 2>&1; then
    error "The current status of your deploy is unhealthy."
    log_line "If you have yet to do so, run '${GREEN}chef-automate dev deployinate${NC}' to deploy Automate."
    log_line "If you have already deployed, there is an issue with your deploy."
    log_line "You can check the logs with '${YELLOW}sl${NC}' and the status with '${YELLOW}chef-automate status${NC}'."
    return 1
  fi

  return 0
}

# Setup ~/.netrc configuration in the studio
#
# We have a dependency with the automate-ui that is a private github repository.
# At this time, NodeJS requires that you either use git+ssh or https w/ a .netrc.
# We are using a .netrc.
#
# Requirements:
# => Habitat 0.54.0 or greater installed
# => Specify `HAB_STUDIO_SECRET_GITHUB_TOKEN` in your shell environment
# ```
# export HAB_STUDIO_SECRET_GITHUB_TOKEN=secret
# ```
generate_netrc_config

# Prepare the environment to run our services
prepare_system() {
  # These are needed for elasticsearch
  mount --bind / / > /dev/null
  install_if_missing core/busybox-static sysctl > /dev/null
  sysctl -w net.ipv6.conf.all.disable_ipv6=1 > /dev/null
  sysctl -w vm.max_map_count=262144 > /dev/null

  # Workaround to start ES in CI systems
  ulimit -n 65536 > /dev/null

  # Set DEVPROXY_URL for automate-ui-devproxy to either localhost or host.docker.internal depending
  # on if we are in a Vagrant-based dev env or a Docker-based dev env, respectively.
  if grep docker /proc/1/cgroup > /dev/null 2>&1; then
    export DEVPROXY_URL="host.docker.internal"
  else
    export DEVPROXY_URL="localhost"
  fi
}

prepare_system

log_old_bindirs() {
  readarray -t old_bindirs < <(find "$GOBIN_BASE" -maxdepth 1 -mindepth 1 -type d -not -path "$GOBIN")
  if [ ${#old_bindirs[@]} -gt 0 ]; then
    warn "The following bin directories are out-dated and can be cleaned up:"
    for old_dir in "${old_bindirs[@]}"; do
      warn "  $old_dir"
    done
  fi
}

log_old_bindirs

# Saves the in memory bash history to a file
save_history() {
  history -a /src/.bash_history
}

# if .studiorc is being sourced from an already running studio, don't reset bash
# history -- this is achieved by saving the current history before it is re-read
save_history

# Load the bash history from a file
history -r /src/.bash_history

cleanup() {
    save_history
    umount /
}

# When exiting the studio save the bash history to a file
trap cleanup EXIT

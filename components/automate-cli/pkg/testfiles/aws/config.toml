# This is a Chef Automate AWS HA mode configuration file. You can run
# 'chef-automate deploy' with this config file and it should
# successfully create a new Chef Automate HA instances with default settings.
[architecture.aws]
## === INPUT NEEDED ===
# Eg.: ssh_user = "ubuntu"
ssh_user = "ec2-user"
# custome ssh porto to connect instances, default will be 22
# Eg.: ssh_port = "22"
ssh_port = "22"
# Private SSH key file path, which has access to all the instances.
# Eg.: ssh_key_file = "~/.ssh/A2HA.pem"
ssh_key_file = "/home/ec2-user/XYZ.pem"
# Eg.: backup_config = "efs" or "s3"
backup_config = "s3"
# If s3 is selected for backup_config,
#    then uncomment and give s3_bucketName
#    or else default chef-automate-ha.<deployment-string> will be used.
# s3_bucketName = ""
## === ===
secrets_key_file = "/hab/a2_deploy_workspace/secrets.key"
secrets_store_file = "/hab/a2_deploy_workspace/secrets.json"
architecture = "aws"
workspace_path = "/hab/a2_deploy_workspace"
# DON'T MODIFY THE BELOW LINE (backup_mount)
backup_mount = "/mnt/automate_backups"
[automate.config]
## === INPUT NEEDED ===
# Password for Automate UI for 'admin' user.
admin_password = "chefautomate"
# Automate Load Balancer FQDN eg.: "chefautomate.example.com"
fqdn = "example.net"
# No. of Automate Frontend Machine or VM eg.: instance_count = "2"
instance_count = "5"
## === ===
#Deprecated Config - automate_setup_type is not supported
# automate_setup_type = "automate"
# teams_port = ""
config_file = "configs/automate.toml"
enable_custom_certs = true
root_ca = "test_root_ca"
public_key = "test_pub_key"
private_key = "test_pri_key"
[chef_server.config]
## === INPUT NEEDED ===
# No. of Chef Server Frontend Machine or VM eg.: instance_count = "2"
instance_count = "1"
# Add Chef Server load balancer root-ca and keys
enable_custom_certs = true
public_key = "test_pub_key"
private_key = "test_pri_key"
# root_ca = ""
# private_key = ""
# public_key = ""
## === ===
[opensearch.config]
## === INPUT NEEDED ===
# No. of OpenSearch DB Backend Machine or VM eg.: instance_count = "3"
instance_count = "3"
# Add OpenSearch load balancer root-ca and keys
enable_custom_certs = true
root_ca = "test_root_ca"
admin_key = "test_pub_key"
admin_cert = "test_pri_key"
public_key = "test_pub_key"
private_key = "test_pri_key"
# root_ca = ""
# private_key = ""
# public_key = ""
## === ===
[postgresql.config]
## === INPUT NEEDED ===
# No. of Postgresql DB Backend Machine or VM eg.: instance_count = "3"
instance_count = "4"
# Add postgresql load balancer root-ca and keys
enable_custom_certs = true
root_ca = "test_root_ca"
public_key = "test_pub_key"
private_key = "test_pri_key"
# root_ca = ""
# private_key = ""
# public_key = ""
## === ===
# ======================================================
[aws.config]
# ============== AWS network Config ============================
## === INPUT NEEDED ===
# Eg.: profile = "default"
profile = "default"
# Eg.: region = "us-east-1"
region = "ap-southeast-2"
# Provide vpcid and cidr block
# Eg.: aws_vpc_id = "vpc12318h"
aws_vpc_id  = "vpc-dsdsdsadsadsa"
#"vpc-c2011ba6"
# Eg.: aws_cidr_block_addr = "172.31.64.0"
aws_cidr_block_addr  = ""
# Eg.: private_custom_subnets = ["subnet-dsdsd", "subnet-e556d5dsdsd13", "subnet-dsdsdsd"]
private_custom_subnets = ["subnet-dsdsds","subnet-dsdsds","subnet-037fd2ec152dsds3bd823"]
# Eg.: public_custom_subnets = ["subnet-dsds", "subnet-p556d513", "subnet-p556d514"]
public_custom_subnets = ["subnet-dsdsdsds","subnet-dsdsdsds","subnet-dsdsdsdsd"]
# ssh key pair name in AWS to access instances
# eg: ssh_key_pair_name = "Enggxxxx"
ssh_key_pair_name = "Enggxxxxx"
## === ===
# ============== Managed Services ======================
## === INPUT NEEDED ===
# in case your are trying to deploy with aws managed
# RDS, and openseach, then make setup_managed_services = true,
# and modify other managed services settings.
setup_managed_services = false
# eg: managed_opensearch_domain_name = "managed-services-os"
managed_opensearch_domain_name = "automate-ha"
# eg: managed_opensearch_domain_url = "search-managed-services-os-eckom3msrwqlmjlgbdu.us-east-1.es.amazonaws.com"
managed_opensearch_domain_url = "vpc-sdsdsddsdsdsdsds.ap-southeast-2.es.amazonaws.com"
# eg: managed_opensearch_username = "admin"
managed_opensearch_username = "chefautomate"
# eg: managed_opensearch_user_password = "dsdsdsdsd@123"
managed_opensearch_user_password = "D4KUofkgjt$Zig1"
# eg: managed_opensearch_certificate = "<cert content>"
managed_opensearch_certificate = ""
# eg: aws_os_snapshot_role_arn = "arn:aws:iam::1127583934333:role/managed-services"
aws_os_snapshot_role_arn = ""
# eg: os_snapshot_user_access_key_id = "AKIA..........PQS7Q7A"
os_snapshot_user_access_key_id = ""
# eg: os_snapshot_user_access_key_secret = "skP4Mqihj....................anAXAX"
os_snapshot_user_access_key_secret = ""
# eg: managed_rds_instance_url = "managed-rds-db.cww4poze5gkx.ap-northeast-1.rds.amazonaws.com:5432"
managed_rds_instance_url = "database-1.sdsdsdsdsdsd.ap-southeast-2.rds.amazonaws.com:5432"
# eg: managed_rds_superuser_username = "postgres"
managed_rds_superuser_username = "masteruser"
# eg: managed_rds_superuser_password = "j7U9$tYA$19$T12"
managed_rds_superuser_password = "j7U9=tYA!19!dsd"
# eg: managed_rds_dbuser_username = "postgres"
managed_rds_dbuser_username = "masteruser"
# eg: managed_rds_dbuser_password = "j7U9$tYA$19$T12"
managed_rds_dbuser_password = "j7U9=tYA!19!T12"
# eg: managed_rds_certificate =
managed_rds_certificate = "<cert content>"
## === ===
# ======================================================
# ============== EC2 Instance Config ===================
# eg: ami_filter_name = ""
ami_filter_name = "amazon"
# Only if we have filter criteria. Best give 'ami_id' below.
ami_filter_virt_type = "hvm"
# Filter ami based on owner.
ami_filter_owner = "137112412989"  #"137112412989"
## === INPUT NEEDED ===
# This AMI should be from the Same Region which we selected above.
# eg: ami_id = "ami-08d4ac5b634553e16" # This ami is of Ubuntu 20.04 in us-east-1
ami_id = "ami-0b55fc9b052b03618"
# eg: automate_server_instance_type = "t3.medium"
automate_server_instance_type = "t3.medium"
# eg: chef_server_instance_type = "t3.medium"
chef_server_instance_type = "t3.medium"
# eg: opensearch_server_instance_type = "m5.large"
opensearch_server_instance_type = "m5.large"
# eg: postgresql_server_instance_type = "t3.medium"
postgresql_server_instance_type = "m5.large"
# eg: automate_lb_certificate_arn = "arn:aws:acm...."
automate_lb_certificate_arn = "dsdsddddddd"
# eg: chef_server_lb_certificate_arn = "arn:aws:acm...."
chef_server_lb_certificate_arn = "dddddddddddddddddd"
# eg: automate_ebs_volume_iops = "100"
automate_ebs_volume_iops = "100"
# eg: automate_ebs_volume_size = "50"
automate_ebs_volume_size = "50"
# eg: automate_ebs_volume_type = "gp3"
automate_ebs_volume_type = "gp3"
# eg: chef_ebs_volume_iops = "100"
chef_ebs_volume_iops = "100"
# eg: chef_ebs_volume_size = "50"
chef_ebs_volume_size = "50"
# eg: chef_ebs_volume_type = "gp3"
chef_ebs_volume_type = "gp3"
# eg: opensearch_ebs_volume_iops = "100"
opensearch_ebs_volume_iops = "100"
# eg: opensearch_ebs_volume_size = "50"
opensearch_ebs_volume_size = "50"
# eg: opensearch_ebs_volume_type = "gp3"
opensearch_ebs_volume_type = "gp3"
# eg: postgresql_ebs_volume_iops = "100"
postgresql_ebs_volume_iops = "100"
# eg: postgresql_ebs_volume_size = "50"
postgresql_ebs_volume_size = "50"
# eg: postgresql_ebs_volume_type = "gp3"
postgresql_ebs_volume_type = "gp3"
## === ===
# Enabale/Disable load balancer logs
# eg lb_access_logs = "false"
lb_access_logs = "false"
# ======================================================
# ============== EC2 Instance Tags =====================
X-Contact = ""
X-Dept = ""
X-Project = ""
# ======================================================
# ============== Deprecated ============================
#Deprecated Config - below config is not supported
#aws_automate_route53_prefix = ""
#aws_chef_server_route53_prefix = ""
#aws_route53_hosted_zone = "saas.chef.io"
#postgresql_db_identifier = ""
#elasticsearch_domain_name = ""
#rds_postgresql_instance_type = "db.t3.medium"
#rds_postgresql_restore_identifier = ""
#datadog_api_key = "DATADOG_API_KEY"
#use_existing_managed_infra = false
#X-Production = "false"
#X-Customer = ""
# ======================================================
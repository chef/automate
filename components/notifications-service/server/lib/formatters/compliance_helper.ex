defmodule Notifications.Formatters.ComplianceHelper do
  @moduledoc "Tools for the management of compliance notifications"
  alias Notifications.Profile
  alias Notifications.ComplianceFailure
  alias Notifications.Formatters.Utils


  @crit_control_threshold 0.7


  # TODO: mp 2017-09-22
  # Note that this is currently tested indirectly in webhook.compliance_test.ex
  # when we examine the payloads - most of which are generated by this module.
  #
  # This code is probably disposable, as this filtering will soon be happening
  # on the sendering side of the notification.
  #
  # If this plan changees, we'll
  # The next round of updates remove a lot of that due to changes in the way we
  # are handling payload testing for formatters.  We'll move the specific
  # success-culling bheavior tests over here, to this module then.

  @doc """
  This removes the following from the failed profiles in the provided ComplianceFailure:
    * all non-critical controls
    * within the controls all tests that are not failed

  In addition, if a control is left with no results (all tests passed) , the control itself
  will be removed from the containing profile.

  Finally, it augments the returned structure as follows:
  * each profile has the field :number_of_controls added, which reflects the
    number of controls in the full profile before it was pruned.
  * each remaining control has the following fields added for compatibility
    with the original usage
  * status - it will always be "failed", because we have filtered out successes.
  * number_of_tests - the original number of tests before pruning
  * number_of_failed_test - the size of the list of remaining results (tests)

  The best part is that this will probably be deleted, as we're moving the filtering to be done
   on the sender's side - it should send only what we need to process a failed compliance notification,
   and the things we prune are not needed by any outbound alerts.

  """
  @spec prune_and_augment(Notifications.ComplianceFailure.t) :: Notifications.ComplianceFailure.t
  def prune_and_augment(%Notifications.ComplianceFailure{} = notification) do
    %{notification | failed_profiles: prune_profiles(notification.failed_profiles, [], @crit_control_threshold)}
  end
  def prune_and_augment(%Notifications.ComplianceFailure{} = notification, control_threshold) do
    %{notification | failed_profiles: prune_profiles(notification.failed_profiles, [], control_threshold)}
  end

  defp prune_profiles([], acc, _control_threshold), do: acc
  defp prune_profiles([profile | profiles], acc, control_threshold) do
    failed_controls = prune_controls(profile.failed_controls, [], control_threshold)
    if length(failed_controls) > 0 do
        prune_controls(profiles, acc, control_threshold)
        additions = %{
          controls: failed_controls,
          number_of_controls: profile.stats.num_tests,
        }
        newprof = profile
                  |> Map.delete(:failed_controls)
                  |> Map.delete(:stats)
                  |> Map.merge(additions)
        prune_profiles(profiles, [newprof| acc], control_threshold)
    else
      prune_profiles(profiles, acc, control_threshold)
    end


  end

  # While all controls we receive have failures, some may not be critical.
  # For critical controls, further prune the results to limit to failures only.
  # For non-critical, drop them from the controls list.
  defp prune_controls([], acc, _impact), do: acc
  defp prune_controls([%Profile.Control{impact: impact} = control | controls], acc, control_threshold) when impact >= control_threshold do
    pruned_results = prune_results(control.failed_results, [])
    stats = control.stats
    additions = %{results: pruned_results,
                  number_of_tests: stats.num_tests,
                  number_of_failed_tests: stats.num_failed_tests,
                  status: "failed"}
    updated_results = control
                      |> Map.delete(:stats)
                      |> Map.delete(:failed_results)
                      |> Map.merge(additions)
    prune_controls(controls, [updated_results | acc], control_threshold)
  end
  # Any control that's not critical gets excluded
  # # TODO - THIS filter must occur prior, because it can prevent
  # # the alert from needing to be triggered.
  defp prune_controls([_control | controls], acc, control_threshold), do: prune_controls(controls, acc, control_threshold)

  # Include only failed tests - that's all we're shipping to the webhook. If the test is not
  # failed it's dropped from the results list. We do know that a provided result will contain
  # at least one failure.
  defp prune_results([], acc), do: acc
  defp prune_results([%Profile.Control.Result{status: "failed"} = result | results], acc) do
    prune_results(results, [result | acc])
  end
  # Anything that's not a failure gets excluded
  defp prune_results([_| results], acc), do: prune_results(results, acc)

end
